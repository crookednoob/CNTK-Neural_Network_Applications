{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convolutional Neural Network with MNIST\n",
    "from IPython.display import display, Image\n",
    "Image(url= \"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env()\n",
    "C.cntk_py.set_fixed_random_seed(1)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data dimensions\n",
    "input_dim_model=(1,28,28) #Images are 28x28 with 1 channel of color (gray)\n",
    "input_dim=28*28 #used by readers to treat the input data as vector\n",
    "num_output_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "\n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "\n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data\\MNIST\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "\n",
    "data_found=False # A flag to indicate if train/test data found in local cache\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"data\", \"MNIST\")]:\n",
    "\n",
    "    train_file=os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "\n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "\n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convolution Layer\n",
    "Image(url=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\", width= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stride = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_padding_strides.gif\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stride = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/cntk103d_same_padding_no_strides.gif\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot images with strides of 2 and 1 with padding turned on\n",
    "images = [(\"https://www.cntk.ai/jup/cntk103d_padding_strides.gif\" , 'With stride = 2'),\n",
    "          (\"https://www.cntk.ai/jup/cntk103d_same_padding_no_strides.gif\", 'With stride = 1')]\n",
    "\n",
    "for im in images:\n",
    "    print(im[1])\n",
    "    display(Image(url=im[0], width=200, height=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN Model Creation\n",
    "x=C.input_variable(input_dim_model)\n",
    "y=C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to build model\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "        h=features\n",
    "        h=C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                num_filters=8,\n",
    "                                strides=(2,2),\n",
    "                                pad=True, name='first_conv')(h)\n",
    "        h=C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                num_filters=16,\n",
    "                                strides=(2,2),\n",
    "                                pad=True, name='second_conv')(h)\n",
    "        r=C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n",
    "        return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of first Convolution Layer:  (8, 14, 14)\n",
      "Bias value of the last Dense Layer:  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Create the model\n",
    "z=create_model(x)\n",
    "\n",
    "#print the output shape/ parameter of different components \n",
    "print(\"Output shape of first Convolution Layer: \", z.first_conv.shape)\n",
    "print(\"Bias value of the last Dense Layer: \", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 11274 parameters in 6 parameter tensors.\n"
     ]
    }
   ],
   "source": [
    "#Number of parameters in this network\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def create_criterion_function(model, labels):\n",
    "    loss=C.cross_entropy_with_softmax(model, labels)\n",
    "    errs=C.classification_error(model, labels)\n",
    "    return loss, errs #(model) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a utility function to compute the moving average sum\n",
    "#A more efficient implementation is possible with np.cumsum function\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "#Define a utility that defines a training progress\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss=\"NA\"\n",
    "    eval_error=\"NA\"\n",
    "    \n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose:\n",
    "            print(\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "\n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Training\n",
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):\n",
    "    #Instantiate the model function; x is the input feature\n",
    "    #We will scale the input image pixels with the range of 0-1 by dividing it with 255\n",
    "    model=model_func(x/255)\n",
    "    \n",
    "    #Instantiate the loss and error function\n",
    "    loss, label_error=create_criterion_function(model, y)\n",
    "    \n",
    "    #Instantiate the trainer object to drive the model training\n",
    "    learning_rate=0.2\n",
    "    lr_schedule=C.learning_parameter_schedule(learning_rate)\n",
    "    learner=C.sgd(z.parameters, lr_schedule)\n",
    "    trainer=C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    #Initialize the parameters for the trainer\n",
    "    minibatch_size=64\n",
    "    num_samples_per_sweep=60000\n",
    "    num_minibatches_to_train=(num_samples_per_sweep*num_sweeps_to_train_with)/minibatch_size\n",
    "    \n",
    "    #Map the data streams to the input and labels\n",
    "    input_map={\n",
    "        y: train_reader.streams.labels,\n",
    "        x: train_reader.streams.features\n",
    "    }\n",
    "    \n",
    "    training_progress_output_freq=500\n",
    "    \n",
    "    #start timer \n",
    "    start=time.time()\n",
    "    \n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        #Read a minibatch form a training data file\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map)\n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "        \n",
    "    #Print training time\n",
    "    print(\"Training took {:.1f} sec\".format(time.time()-start))\n",
    "    \n",
    "    #test the model\n",
    "    test_input_map={\n",
    "        y: test_reader.streams.labels,\n",
    "        x: test_reader.streams.features\n",
    "    }\n",
    "    \n",
    "    #Test data for trained model\n",
    "    test_minibatch_size=512\n",
    "    num_samples=10000\n",
    "    num_minibatches_to_test=num_samples//test_minibatch_size\n",
    "    \n",
    "    test_result=0.0\n",
    "    \n",
    "    for i in range(num_minibatches_to_test):\n",
    "        \n",
    "        #We are loading test data in batches specified by test_minibatch_size\n",
    "        #Each datapoint in the minibatch is a MNIST digit image of 784 dimensions\n",
    "        #with one pixel per dimension which will encode/decode with the trained model\n",
    "        data=test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error=trainer.test_minibatch(data)\n",
    "        test_result=test_result+eval_error\n",
    "    \n",
    "    #Average of evaluation errors of all test minibatches\n",
    "    print(\"Average test error: {:.2f}%\".format(test_result*100/num_minibatches_to_test))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 2.3093, Error: 89.06%\n",
      "Minibatch: 500, Loss: 0.2081, Error: 7.81%\n",
      "Minibatch: 1000, Loss: 0.1345, Error: 4.69%\n",
      "Minibatch: 1500, Loss: 0.1095, Error: 3.12%\n",
      "Minibatch: 2000, Loss: 0.0259, Error: 0.00%\n",
      "Minibatch: 2500, Loss: 0.0036, Error: 0.00%\n",
      "Minibatch: 3000, Loss: 0.0094, Error: 0.00%\n",
      "Minibatch: 3500, Loss: 0.0484, Error: 1.56%\n",
      "Minibatch: 4000, Loss: 0.0214, Error: 0.00%\n",
      "Minibatch: 4500, Loss: 0.0403, Error: 1.56%\n",
      "Minibatch: 5000, Loss: 0.0155, Error: 1.56%\n",
      "Minibatch: 5500, Loss: 0.0020, Error: 0.00%\n",
      "Minibatch: 6000, Loss: 0.0126, Error: 0.00%\n",
      "Minibatch: 6500, Loss: 0.0167, Error: 0.00%\n",
      "Minibatch: 7000, Loss: 0.0207, Error: 1.56%\n",
      "Minibatch: 7500, Loss: 0.0021, Error: 0.00%\n",
      "Minibatch: 8000, Loss: 0.0024, Error: 0.00%\n",
      "Minibatch: 8500, Loss: 0.0174, Error: 0.00%\n",
      "Minibatch: 9000, Loss: 0.0313, Error: 1.56%\n",
      "Training took 102.4 sec\n",
      "Average test error: 1.46%\n"
     ]
    }
   ],
   "source": [
    "#Run the Trainer and Test Model\n",
    "def do_train_test():\n",
    "    global z\n",
    "    z= create_model(x)\n",
    "    reader_train= create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test= create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "    \n",
    "    \n",
    "    \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias value of the last dense layer:  [-0.02137667 -0.05231637  0.0724031  -0.07259671 -0.02112111 -0.06834911\n",
      " -0.00605507 -0.12185648  0.25030175  0.04093128]\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias value of the last dense layer: \", z.classify.b.value) #It must be non-zero as it is updating. Previously it was set to \n",
    "#zero before running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run evaluation/Prediction\n",
    "out= C.softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data for evaluation\n",
    "reader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size=25\n",
    "eval_input_map= {\n",
    "    x: reader_eval.streams.features, \n",
    "    y: reader_eval.streams.labels\n",
    "}\n",
    "\n",
    "data=reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label=data[y].asarray()\n",
    "img_data=data[x].asarray()\n",
    "\n",
    "#Reshape the img_data to M x 1 x 28 x 28 to be comaptible with the model\n",
    "img_data=np.reshape(img_data, (eval_minibatch_size, 1,28,28))\n",
    "\n",
    "predicted_label_prob=[out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the index with maximum value for the predicted as well as the ground truth\n",
    "pred= [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel=[np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4]\n",
      "Predicted: [7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a random image\n",
    "sample_number=6\n",
    "plt.imshow(img_data[sample_number].reshape(28, 28), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred= gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label:\", img_pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pooling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/c103d_max_pooling.gif\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average pooling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.cntk.ai/jup/c103d_average_pooling.gif\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot images with strides of 2 and 1 with padding turned on\n",
    "images = [(\"https://www.cntk.ai/jup/c103d_max_pooling.gif\" , 'Max pooling'),\n",
    "          (\"https://www.cntk.ai/jup/c103d_average_pooling.gif\", 'Average pooling')]\n",
    "\n",
    "for im in images:\n",
    "    print(im[1])\n",
    "    display(Image(url=im[0], width=300, height=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch: 0, Loss: 2.3725, Error: 89.06%\n",
      "Minibatch: 500, Loss: 0.1950, Error: 10.94%\n",
      "Minibatch: 1000, Loss: 0.1154, Error: 1.56%\n",
      "Minibatch: 1500, Loss: 0.0428, Error: 1.56%\n",
      "Minibatch: 2000, Loss: 0.0143, Error: 0.00%\n",
      "Minibatch: 2500, Loss: 0.0266, Error: 1.56%\n",
      "Minibatch: 3000, Loss: 0.0102, Error: 0.00%\n",
      "Minibatch: 3500, Loss: 0.0530, Error: 1.56%\n",
      "Minibatch: 4000, Loss: 0.0093, Error: 0.00%\n",
      "Minibatch: 4500, Loss: 0.0387, Error: 1.56%\n",
      "Minibatch: 5000, Loss: 0.0337, Error: 1.56%\n",
      "Minibatch: 5500, Loss: 0.0019, Error: 0.00%\n",
      "Minibatch: 6000, Loss: 0.0086, Error: 0.00%\n",
      "Minibatch: 6500, Loss: 0.0094, Error: 0.00%\n",
      "Minibatch: 7000, Loss: 0.0191, Error: 0.00%\n",
      "Minibatch: 7500, Loss: 0.0063, Error: 0.00%\n",
      "Minibatch: 8000, Loss: 0.0013, Error: 0.00%\n",
      "Minibatch: 8500, Loss: 0.0138, Error: 0.00%\n",
      "Minibatch: 9000, Loss: 0.0259, Error: 3.12%\n",
      "Training took 84.6 sec\n",
      "Average test error: 1.09%\n"
     ]
    }
   ],
   "source": [
    "#Create a network with MaxPooling\n",
    "\n",
    "#Modify the model\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.layers.glorot_uniform(), activation=C.relu):\n",
    "        h=features\n",
    "        h=C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                num_filters=8,\n",
    "                                strides=(1,1),\n",
    "                                pad=True,\n",
    "                                name=\"first_conv\")(h)\n",
    "        h=C.layers.MaxPooling(filter_shape=(2,2),\n",
    "                            strides=(2,2),\n",
    "                            name=\"first_max\")(h)\n",
    "        h=C.layers.Convolution2D(filter_shape=(5,5),\n",
    "                                num_filters=16,\n",
    "                                strides=(1,1),\n",
    "                                pad=True,\n",
    "                                name=\"second_conv\")(h)\n",
    "        h=C.layers.MaxPooling(filter_shape=(3,3),\n",
    "                             strides=(3,3),\n",
    "                             name=\"second_max\")(h)\n",
    "        r=C.layers.Dense(num_output_classes, activation=None, name=\"classify\")(h)\n",
    "        return r\n",
    "    \n",
    "do_train_test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
